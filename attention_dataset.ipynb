{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0721858-b1e4-42f9-b7d5-d172d4051bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176060, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_attention_data = pd.read_csv('attention_data.csv')\n",
    "final_attention_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca621a-90f6-4ad5-a67e-873e67f1ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: a folder that contains scenes splitted from an advertising video\n",
    "# the name of the folder is the video id\n",
    "\n",
    "### DESCRIPTION OF THE FOLLOWING CODES ###\n",
    "# to estimate human attention within the scene\n",
    "# Human attention is guided by meaning maps (semantic richness) stated by T.R. Henderson (2017)\n",
    "# we aim to simulates their lab experiment procedure by\n",
    "# 1) first separating the scene image into several patches\n",
    "\n",
    "# output dir: for patch, cuts_patch/[video_id]\n",
    "#             for metadata, metadata/[video_id]\n",
    "\n",
    "# GPU accelerated\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "import cv2\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "def create_circular_masks(h, w, centers, radii):\n",
    "    Y, X = cp.ogrid[:h, :w]\n",
    "    centers = cp.asarray(centers)\n",
    "    radii = cp.asarray(radii)\n",
    "    \n",
    "    X = X[:, :, cp.newaxis] - centers[:, 0]\n",
    "    Y = Y[:, :, cp.newaxis] - centers[:, 1]\n",
    "    \n",
    "    dist_from_centers = cp.sqrt(X**2 + Y**2)\n",
    "    masks = dist_from_centers <= radii\n",
    "    return masks\n",
    "\n",
    "def extract_circular_patches(scene_name, image, degrees, overlap=0.1, save_dir_patch=\"raw/test\", save_dir_meta=\"raw/test\", batch_size=100):\n",
    "    if not os.path.exists(save_dir_patch):\n",
    "        os.makedirs(save_dir_patch)\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    metadata = []\n",
    "\n",
    "    # Move image to GPU\n",
    "    image_gpu = cp.asarray(image)\n",
    "\n",
    "    for degree in degrees:\n",
    "        radius = degree_to_pixel(degree, h, w)\n",
    "        step = int(radius * (1 - overlap))\n",
    "        \n",
    "        centers = [(x, y) for y in range(0, h, step) for x in range(0, w, step)]\n",
    "        radii = [radius] * len(centers)\n",
    "        \n",
    "        # Process in batches\n",
    "        for i in range(0, len(centers), batch_size):\n",
    "            batch_centers = centers[i:i+batch_size]\n",
    "            batch_radii = radii[i:i+batch_size]\n",
    "            \n",
    "            masks = create_circular_masks(h, w, batch_centers, batch_radii)\n",
    "            \n",
    "            for j, (center, mask) in enumerate(zip(batch_centers, masks.transpose(2, 0, 1))):\n",
    "                patch = cp.zeros_like(image_gpu)\n",
    "                patch[mask] = image_gpu[mask]\n",
    "\n",
    "                coords = cp.argwhere(mask)\n",
    "                y_min, x_min = coords.min(axis=0)\n",
    "                y_max, x_max = coords.max(axis=0)\n",
    "\n",
    "                cropped_patch = patch[y_min:y_max+1, x_min:x_max+1]\n",
    "                patch_image = Image.fromarray(cp.asnumpy(cropped_patch))\n",
    "                patch_filename = f'patch_{i+j}_deg_{degree}.png'\n",
    "                patch_image.save(os.path.join(save_dir_patch, patch_filename))\n",
    "\n",
    "                metadata.append({\n",
    "                    'filename': patch_filename,\n",
    "                    'center': center,\n",
    "                    'radius': int(radius),\n",
    "                    'bbox': (int(x_min), int(y_min), int(x_max), int(y_max))\n",
    "                })\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    # Save metadata to a file\n",
    "    np.save(os.path.join(save_dir_meta, f'{scene_name}_metadata.npy'), metadata)\n",
    "\n",
    "def degree_to_pixel(degree, h, w):\n",
    "    fov = 90  # Example field of view in degrees\n",
    "    return int((degree / fov) * min(h, w))\n",
    "\n",
    "def reconstruct_image(metadata_file, original_shape):\n",
    "    metadata = np.load(metadata_file, allow_pickle=True)\n",
    "    reconstructed_image = cp.zeros(original_shape, dtype=cp.uint8)\n",
    "\n",
    "    centers = [data['center'] for data in metadata]\n",
    "    radii = [data['radius'] for data in metadata]\n",
    "    masks = create_circular_masks(original_shape[0], original_shape[1], centers, radii)\n",
    "\n",
    "    for i, data in enumerate(metadata):\n",
    "        patch_image = cv2.imread(os.path.join(os.path.dirname(metadata_file), data['filename']))\n",
    "        patch_image = cv2.cvtColor(patch_image, cv2.COLOR_BGR2RGB)\n",
    "        patch_array = cp.asarray(patch_image)\n",
    "\n",
    "        x_min, y_min, x_max, y_max = data['bbox']\n",
    "        mask_cropped = masks[y_min:y_max+1, x_min:x_max+1, i]\n",
    "\n",
    "        reconstructed_image[y_min:y_max+1, x_min:x_max+1][mask_cropped] = patch_array[mask_cropped]\n",
    "\n",
    "    return Image.fromarray(cp.asnumpy(reconstructed_image))\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file = os.path.join(log_dir, f\"processing_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Redirect tqdm output to log file\n",
    "class TqdmToLogger(object):\n",
    "    def __init__(self, logger, level=logging.INFO):\n",
    "        self.logger = logger\n",
    "        self.level = level\n",
    "        self.last_msg = ''\n",
    "\n",
    "    def write(self, buf):\n",
    "        self.last_msg = buf.strip()\n",
    "\n",
    "    def flush(self):\n",
    "        self.logger.log(self.level, self.last_msg)\n",
    "\n",
    "tqdm_logger = TqdmToLogger(logging.getLogger())\n",
    "\n",
    "# Main execution\n",
    "logging.info(\"Starting processing\")\n",
    "attention_data = pd.read_csv('attention_data.csv')\n",
    "video_ids = attention_data['video id'].unique()\n",
    "\n",
    "for video_id in tqdm(video_ids[3162:], desc=\"Processing videos\", file=tqdm_logger):\n",
    "    video_id = str(video_id)\n",
    "    scenes_path = os.path.join(\"scene_cuts\", video_id)\n",
    "    output_patch_dir = os.path.join(\"cuts_patch\", video_id)\n",
    "    output_metadata_dir = os.path.join(\"cuts_metadata\", video_id)\n",
    "    \n",
    "    if not os.path.exists(output_patch_dir):\n",
    "        os.makedirs(output_patch_dir)\n",
    "    if not os.path.exists(output_metadata_dir):\n",
    "        os.makedirs(output_metadata_dir)\n",
    "\n",
    "    # Get list of already processed scenes\n",
    "    processed_scenes = set(os.path.splitext(f)[0] for f in os.listdir(output_metadata_dir) if f.endswith('_metadata.npy'))\n",
    "\n",
    "    for scene_filename in tqdm(os.listdir(scenes_path), desc=f\"Processing scenes for video {video_id}\", leave=False, file=tqdm_logger):\n",
    "        scene_name, _ = os.path.splitext(scene_filename)\n",
    "        \n",
    "        # Skip if this scene has already been processed\n",
    "        if scene_name in processed_scenes:\n",
    "            logging.info(f\"Skipping already processed scene: {scene_name}\")\n",
    "            continue\n",
    "\n",
    "        scene_path = os.path.join(scenes_path, scene_filename)\n",
    "\n",
    "        # Load the scene image using OpenCV for faster loading\n",
    "        scene_image_np = cv2.imread(scene_path)\n",
    "        if scene_image_np is None:\n",
    "            logging.error(f\"Failed to load image: {scene_path}\")\n",
    "            continue\n",
    "        scene_image_np = cv2.cvtColor(scene_image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Define the output directories for patches and metadata\n",
    "        scene_patch_dir = os.path.join(output_patch_dir, scene_name)\n",
    "        metadata_dir = output_metadata_dir\n",
    "\n",
    "        try:\n",
    "            # Extract patches and save metadata\n",
    "            extract_circular_patches(scene_name, scene_image_np, degrees=[3, 7],\n",
    "                                     save_dir_patch=scene_patch_dir,\n",
    "                                     save_dir_meta=metadata_dir,\n",
    "                                     batch_size=100)  # Adjust batch_size as needed\n",
    "            logging.info(f\"Successfully processed scene: {scene_name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing scene {scene_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Clear GPU memory after processing each video\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "logging.info(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40fffa-9c2f-4e33-bccc-238a65b9384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  75%|███████▌  | 377/500 [44:28<11:11,  5.46s/it]  "
     ]
    }
   ],
   "source": [
    "# 2) then, store the patch information to .csv file\n",
    "# output dir: patch_info_dir\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_patch_scores_for_scenes(patch_data_folder, metadata_folder, output_csv):\n",
    "    # Prepare CSV file\n",
    "    with open(output_csv, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['scene', 'filename', 'center_x', 'center_y', 'radius', 'bbox_x_min', 'bbox_y_min', 'bbox_x_max', 'bbox_y_max', 'mean_score'])\n",
    "\n",
    "        # Iterate through each scene\n",
    "        for scene_name in os.listdir(patch_data_folder):\n",
    "            scene_folder = os.path.join(patch_data_folder, scene_name)\n",
    "            metadata_file = os.path.join(metadata_folder, f\"{scene_name}_metadata.npy\")\n",
    "\n",
    "            if not os.path.exists(metadata_file):\n",
    "                print(f\"Metadata file for scene {scene_name} not found, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load metadata\n",
    "            metadata = np.load(metadata_file, allow_pickle=True)\n",
    "\n",
    "            # Iterate through each patch\n",
    "            for data in metadata:\n",
    "                patch_image = Image.open(os.path.join(scene_folder, data['filename'])).convert('L')\n",
    "                patch_array = np.array(patch_image)\n",
    "\n",
    "                # Write data to CSV\n",
    "                writer.writerow([\n",
    "                    scene_name,\n",
    "                    data['filename'],\n",
    "                    data['center'][0], data['center'][1],\n",
    "                    data['radius'],\n",
    "                    data['bbox'][0], data['bbox'][1], data['bbox'][2], data['bbox'][3],\n",
    "                ])\n",
    "\n",
    "                \n",
    "cuts_patch_folder = 'cuts_patch'\n",
    "cuts_metadata_folder = 'cuts_metadata'\n",
    "\n",
    "\n",
    "cuts_patch_files = os.listdir(cuts_patch_folder)\n",
    "for video_id in tqdm(cuts_patch_files[:500], desc=\"Processing videos\"):\n",
    "    patch_data_folder = os.path.join(cuts_patch_folder, video_id)\n",
    "    metadata_folder = os.path.join(cuts_metadata_folder, video_id)\n",
    "    output_csv = f'patch_info_dir/patch_info_{video_id}.csv'\n",
    "    calculate_patch_scores_for_scenes(patch_data_folder, metadata_folder, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
